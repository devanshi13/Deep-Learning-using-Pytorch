{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch-2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bfU-AYJYq8o"
      },
      "source": [
        "### **Autograd**\n",
        "\n",
        "- It is an automatic differentitaion engine in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "990mo0OaYhXF"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_4_qFQqY8xw"
      },
      "source": [
        "# requires_grad - Is True if gradients need to be computed for this Tensor\n",
        "a = torch.tensor([5.], requires_grad=True)\n",
        "b = torch.tensor([6.], requires_grad=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyPTRmJiZKx_",
        "outputId": "d1633f81-b16e-4b3f-df7a-2958cc241574"
      },
      "source": [
        "a"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDum_WzsZLQe",
        "outputId": "3e29002f-454e-4c98-8378-d36e5ec9bf5f"
      },
      "source": [
        "b"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NntbMRICZLmQ"
      },
      "source": [
        "y = a**3 - b**2"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgexEO5HZQBU",
        "outputId": "34ffc81d-6853-4db5-d84f-93f7c0d52007"
      },
      "source": [
        "y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([89.], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIRbLLbyZQZH"
      },
      "source": [
        "# dy/da = 3*a**2 = 75\n",
        "# dy/db = 2**b = -12"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VrlUh0Lc6fR"
      },
      "source": [
        "#### **Gradients can't be calculated until we perform backward pass**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeeUoVKJZhjQ",
        "outputId": "4eddc994-8668-45ca-cd19-efebb7082599"
      },
      "source": [
        "# calculate gradient using tensor_name.grad()\n",
        "print(a.grad)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESuPC6qYZk9H",
        "outputId": "e562b2b9-209f-4089-c1ec-98da5fa6ea16"
      },
      "source": [
        "print(b.grad)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7UudEoadD54"
      },
      "source": [
        "#### **Performing backward pass and calculating gradient**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujxhsvlfZnEZ"
      },
      "source": [
        "# Backward Pass\n",
        "y.backward()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTmdCc5UZpYy",
        "outputId": "241cc443-a55d-458a-fae4-aa56d75d3032"
      },
      "source": [
        "print(a.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([75.])\n",
            "tensor([-12.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9pZBpd4dVG0"
      },
      "source": [
        "#### **Let's try on a simple equation -**\n",
        "y=w*x+b "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbAQ2hyEZtdJ",
        "outputId": "004104be-5a6f-4c67-da18-eb0ae65bab04"
      },
      "source": [
        "w = torch.randn(10, 1, requires_grad=True)\n",
        "w"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.2565],\n",
              "        [-1.1536],\n",
              "        [ 0.4455],\n",
              "        [ 0.0591],\n",
              "        [-0.0674],\n",
              "        [ 1.1324],\n",
              "        [-1.3814],\n",
              "        [ 0.6829],\n",
              "        [ 0.1139],\n",
              "        [-0.9607]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vprBQy-xahV7",
        "outputId": "b233ae5b-ad0b-4241-b1a1-9731b3fd68d8"
      },
      "source": [
        "x = torch.randn(1, 10, requires_grad=True)\n",
        "x"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9297,  2.8417, -1.0044,  0.3722, -0.4546,  0.1745,  0.5309, -1.0483,\n",
              "          0.5504, -0.4810]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crQESABcbxui",
        "outputId": "56b53bcd-e9a1-4192-8a69-324615c62a5f"
      },
      "source": [
        "output = torch.matmul(x, w)+b\n",
        "output"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4321]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubHeZexIb7Ky",
        "outputId": "c86c2a37-bc06-406f-d891-9c291d7c65b8"
      },
      "source": [
        "loss = 1 - output\n",
        "loss"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5679]], grad_fn=<RsubBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOY9dRkxcIFk"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQyrcBtQcQr9",
        "outputId": "0e0b068e-f9f5-4cb2-c29a-c5ffaad20fc5"
      },
      "source": [
        "w.grad"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9297],\n",
              "        [-2.8417],\n",
              "        [ 1.0044],\n",
              "        [-0.3722],\n",
              "        [ 0.4546],\n",
              "        [-0.1745],\n",
              "        [-0.5309],\n",
              "        [ 1.0483],\n",
              "        [-0.5504],\n",
              "        [ 0.4810]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSXvhXuXcSIE"
      },
      "source": [
        "# torch.no_grad() basically skips the gradient calculation over the weights\n",
        "# reduces memory consumption\n",
        "# the result of every computation will have requires_grad=False, even when the inputs have requires_grad=True.\n",
        "with torch.no_grad():\n",
        "  w = w - 0.001 * w.grad.data"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfjjTOtBckNm",
        "outputId": "cabb2694-c289-4397-ec28-1f7893c8770f"
      },
      "source": [
        "w"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.2556],\n",
              "        [-1.1507],\n",
              "        [ 0.4444],\n",
              "        [ 0.0595],\n",
              "        [-0.0679],\n",
              "        [ 1.1326],\n",
              "        [-1.3809],\n",
              "        [ 0.6818],\n",
              "        [ 0.1145],\n",
              "        [-0.9612]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCzWnfHff6z0"
      },
      "source": [
        "#### **no_grad function**\n",
        "\n",
        "- To stop PyTorch from tracking the history and forming the backward graph, the code can be wrapped inside with torch.no_grad() \n",
        "- It will make the code run faster whenever gradient tracking is not needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH_7NjX5crIq"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}